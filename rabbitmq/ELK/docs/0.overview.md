# ELK (Elasticsearch-Logstash-Kibana)
- `ELK` là ứng dụng được tạo nên bằng cách kết hợp các thành phần xử lý khác nhau:
    + `Elasticsearch:` lưu trữ và đánh chỉ mục dữ liệu.
    + `Logstash:` tập trung và phân tích Log.
    + `Kibana:` Hiển trị truy vấn theo dạng đồ thị.
- Cơ chế hoạt động của `ELK stack`
    + Đầu tiên log sẽ được đưa đến `logstash` (server gửi UDP request chứa log tới URL của logstash hoặc beat đọc file log và gửi lên Logstash)
    + `Logstash` sẽ đọc những Log này, thêm các thông tin như thời gian, IP, parse dữ liệu từ log sau đó khi xuống database là `Elasticsearch`.
    + Khi muốn xem log, người dùng vào URL của Kibana. Kibana sẽ đọc thông tin log trong Elasticsearch, hiển thị cho người dùng query và xử lý.
## 1. Cơ chế
- Dữ liệu được các `Beats` thu thập và gửi về cho `Logstash` -> `Logstash` tiếp nhận và phân tích dữ liệu -> `Logstash` gửi dữ liệu vào `Elasticsearch` -> `Elasticsearch` nhận dữ liệu từ `Logstash` rồi lưu trữ, đánh chỉ mục -> `Kibana` sử dụng các dữ liệu trong `Elasticsearch` để hiển thị và phân tích cú pháp tìm kiếm mà người dùng nhập vào để gửi cho `Elasticsearch` tìm kiếm.
**`Beats` -> `Logstash` -> `Elasticsearch` -> `Kibana`**

## 2. Beats
- Chạy trên `Client` để thu thập dữ liệu.
- Các `Beats` được cung cấp sẵn bởi Elastic:
  + `Filebeat`: đọc file và lưu vị trí cuối cùng, khi có dữ liệu mới sẽ đọc tiếp và gửi.
  + `Packetbeat:` capture gói tin trên các port của client, chuyển tiếp dữ liệu về `Logstash`.
  + `Topbeat (metricbeat):` thu thập dữ liệu về tài nguyên hệ thống client và gửi về `Logstash`.

## 3. Logstash
- Nhận dữ liệu từ các `beats`, tiến hành phân tích dữ liệu.
- Phân tích dữ liệu gửi từ `filebeat` bằng `grok`.
- `Grok` là một dạng khai báo pattern sử dụng regular expression.
- Dữ liệu được gửi sang cho `Elasticsearch` để lưu trữ.
- `Logstash` luôn có 3 phần: Input, Filter, Output.
- `grok` là một dạng Filter để phân tích dữ liệu.
- Khi cấu hình `Logstash` luôn có 3 phần là: Input, Filter, Output.

![](https://assets.digitalocean.com/articles/elastic_1804/logstash_pipeline_updated.png)

## 4. Elasticsearch
- Thực hiện lưu trữ và đánh chỉ mục dữ liệu.
- Sử dụng các template để lưu trữ dữ liệu.
- Có thể cấu hình cluster, shard, replica để tăng tính an toàn, tính sẵn sàng, tăng hiệu năng đánh chỉ mục, tăng hiệu năng tìm kiếm dữ liệu.
- `Elasticsearch` là một `Restful distributed search engine` -> cung cấp khả năng tìm kiếm phân tán thông qua  API, lưu trữ dữ liệu dạng NoSQL database (cơ sở dữ liệu phi cấu trúc)

### A Distributed RESRful Search Engine


## 5. Kibana
- Hiển thị dữ liệu theo thời gian thực.
- Hỗ trợ tìm kiếm dữ liệu nhiều kiểu.
- Hiển thị dữ liệu theo dạng biểu đồ.

## 6. Production
- ELK trên môi trường Production
  + Sử dụng `Redis` để nhận dữ liệu từ `beats`.
  + Chuyển tiếp dữ liệu từ `Redis` vào `Logstash`.
  + Cài đặt `Redis` và `Logstash` tại một node riêng.
  + Cài đặt `Elasticsearch` trên 2 node và khai báo `Replica` là 2.
  + `Kibana` nên cài đặt cùng nginx trên một node riêng để hỡ trợ user đăng nhập và hiển thị.
  + Sử dụng `VIP` cho `Elasticsearch`.
  + Optimized `Elasticsearch` để tăng hiệu năng:
    - limit open file
    - heap size process
    - read write disk

![](https://i.ibb.co/g9HXj2m/Screenshot-from-2021-10-08-10-16-38.png)

![](https://i.ibb.co/4YjFpYV/Screenshot-from-2021-10-08-16-12-50.png)




